from nltk.tokenize import word_tokenizer

txt = """This is a Word Tokenizer Example No. 1.23"""

word_tokenize(txt)
